---
title: "LISTA 2"
subtitle: "ESTATÍSTICA COMPUTACIONAL"
author: "Tailine J. S. Nonato"
date: "10/28/2023"
format: html
---

```{r}
#| message: false
#| echo: false
if (!require(pacman)) install.packages("pacman")
pacman::p_load(tidyverse,bayesmeta)
```

## 1) Discrete Inverse Transform: Rizzo 3.5
A discrete random variable X has probability mass function
$$\begin{matrix}
 x & 0 & 1 & 2 & 3 & 4 \\ \hline 
 f(x) & 0.1 & 0.2 & 0.2 & 0.2 & 0.3
\end{matrix}
$$ 

Use the inverse transform method to generate a random sample of size 1000 from the distribution of X. Construct a relative frequency table and compare the empirical with the theoretical probabilities. Repeat using the R sample function.

**Solution**

De acordo com o livro texto, "for each random variate required:

1. Generate a random $u$ from $Uniform(0,1)$.

2. Deliver $x_{i}$ where $F(x_{i−1}) < u ≤ F(x_{i})$."

Assim, agregando algumas informações do livro, tem-se que:

```{r}
#| warning: false
n <- 1000
p <- c(0.1,0.2,0.2,0.2,0.3)
u <- runif(n) 
x <- as.integer(u > p)
se<- sqrt(p*(1-p)/n)
round(rbind(table(x)/n, p, se),3)
```

Nos resultados acima, a primeira linha corresponde as frequências relativas da amostra, a segunda linha a distribuição teórica e a terceira ao erro padrão.

## 2) Acceptance-Rejection: Rizzo 3.7
Write a function to generate a random sample of size n from the $Beta(a, b)$ distribution by the acceptance-rejection method. Generate a random sample of size 1000 from the $Beta(3,2)$ distribution. Graph the histogram of the sample with the theoretical $Beta(3,2)$ density superimposed.

**Solution**

```{r}
n <- 1000
k <- 0 #counter for accepted 
j <- 0 #iterations
y <- numeric(n)
while (k < n) {
u <- runif(1)
j <- j + 1
x <- runif(1) #random variate from g 
if (x * (1-x) > u) {
            #we accept x
            k <- k + 1
            y[k] <- x
}}
```

Antes de partir para a comparação, nota-se que foram necessárias `r j` iterações para gerar `r n` variavéis Beta.

Utilizando ainda as ideias apresentadas no livro:

```{r}
#compare empirical and theoretical percentiles
p <- seq(.1, .9, .1) 
Qhat <- quantile(y, p) #quantiles of sample
Q <- qbeta(p, 3, 2) #theoretical quantiles
se <- sqrt(p * (1-p) /(n * dbeta(Q, 3, 2))) #see Ch. 1

round(rbind(Qhat, Q, se), 3)
```

Assim como na questão anterior, nos resultados acima, a primeira linha corresponde as frequências relativas da amostra, a segunda linha a distribuição teórica e a terceira ao erro padrão.

## 3) Multivariate Normal: Rizzo 3.14

Generate 200 random observations from the 3-dimensional multivariate normal distribution having mean vector $\mu = (0, 1, 2)$ and covariance matrix 


$$\sum = \begin{bmatrix}
 1 & -0.5 & 0.5\\
 -0.5 & 1 & -0.5\\
 0.5 & -0.5 & 1
\end{bmatrix}
$$ 

using the Choleski factorization method. Use the R pairs plot to graph an array of scatter plots for each pair of variables.

For each pair of variables, 96 Statistical Computing with R (visually) check that the location and correlation approximately agree with the theoretical parameters of the corresponding bivariate normal distribution.

**Solution**

Seguindo o exemplo 3.18 do livro texto, tem-se que a função para o Método da Fatoração de Choleski para gerar amostras de Distribuição Normal N-Dimensional pode ser escrita por:

```{r}
rmvn.Choleski <-
function(n, mu, Sigma) {
# generate n random vectors from MVN(mu, Sigma)
# dimension is inferred from mu and Sigma
d <- length(mu) 
Q <- chol(Sigma) # Choleski factorization of Sigma
Z <- matrix(rnorm(n*d), nrow=n, ncol=d)
X <- Z %*% Q + matrix(mu, n, d, byrow=TRUE)
X
}

```

Agora adicionando os dados informados no enunciado e rodando a função são geradas listas:

```{r}
#| label: pairs
#| fig-cap: "Sample Scartter Plots"

n <- 200
mu <- c(0,1,2)
sigma <- matrix(c(1,-.5,.5,-.5,1,-.5,.5,-.5,1),nrow=3)
x<-rmvn.Choleski(n,mu,sigma)

head(x)
```

E então os gráficos de dispersão dos valores gerados são dados por:

```{r}
pairs(x)
```

## 4) Antithetic Variables: Rizzo 5.6
In Example 5.7 the control variate approach was illustrated for Monte Carlo integration of
$$θ = \int_{0}^{1} e^x dx.$$
Now consider the antithetic variate approach. 

Compute $Cov(e^U , e^{1−U} )$ and $Var(e^U + e^{1−U} )$, where $U∼ Uniform(0,1)$. What is the percent reduction invariance of $\theta$ that can be achieved using antithetic variates (compared with simple MC)?

**Solution**

No solutions


## 5) Importance Sampling: Rizzo 5.13, Rizzo 5.14 e Rizzo 5.15

### Rizzo 5.13
Find two importance functions f1 and f2 that are supported on (1, ∞) and
are ‘close’ to
$$g(x) = \frac{x^2}{\sqrt 2 \pi} e^{−x^{2}/2}, \hspace{1cm} x>1$$
Which of your two importance functions should produce the smaller variance in estimating
$$\int_{1}^{\infty} \frac{x^2}{\sqrt 2 \pi} e^{−x^{2}/2} dx$$
by importance sampling? Explain.

**Solution**

```{r}
g = function (x) {
  x ^ 2 / sqrt(2*pi) * exp(-x^2/2)
}

xs = seq(0,10,0.1)

ys.g = g(xs)
ys.rayleigh = drayleigh(xs)
ys.norm = dnorm(xs, mean = 1.5)
lim = max(c(ys.g, ys.rayleigh, ys.norm))

plot(xs, ys.g, type = "l", ylim = c(0, lim))
lines(xs, ys.rayleigh, col="red", ylim = c(0, lim))
lines(xs, ys.norm, col="blue", ylim = c(0, lim))

#f1(x) = drayleigh(x, sigma=1.5)
#f2(x) = dnorm(x, mean = 1.5)

# f2 is a little closer to g. should be better.
```

### Rizzo 5.14
Obtain a Monte Carlo estimate of
$$ \int_{1}^{\infty} \frac{x^2}{\sqrt 2 \pi} e^{−x^{2}/2} dx $$
by importance sampling.

**Solution**

```{r}
g = function (x) {
  x ^ 2 / sqrt(2*pi) * exp(-x^2/2) * (x > 1)
}

sigma.rayleigh = 1.5
mean = 1.5
n = 10000

f1 = function (x) {
  drayleigh(x) * (x > 1)
}

f2 = function (x) {
  dnorm(x, mean = mean) * (x > 1)
}

rf1 = function () {
  rrayleigh(n)
}

rf2 = function () {
  rnorm(n, mean = mean)
}

is.rayleigh = function () {
  xs = rf1()
  return(mean(g(xs)/f1(xs), na.rm = TRUE))  
}

is.norm = function () {
  xs = rf2()
  return(mean(g(xs)/f2(xs), na.rm = TRUE))  
}

(theta1 = is.rayleigh())
(theta2 = is.norm())
(truth = 0.400626)
```

### Rizzo 5.15
Obtain the stratified importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.

**Solution**

No solutions

## 6) Monte Carlo Estimation: Rizzo 6.1

Estimate the $MSE$ of the level $k$ trimmed means for random samples of size 20 generated from a standard Cauchy distribution. (The target parameter $\theta$ is the center or median; the expected value does not exist.) Summarize the estimates of $MSE$ in a table for $k = 1,2,...,9$.

**Solution**

Usando o exemplo 6.3 do livro texto, tem-se que:

```{r}
n <- 20
K <- n/2 - 1
m <- 1000
mse <- matrix(0, n/2, 6)

trimmed.mse <- function(n, m, k, p) {
tmean <- numeric(m)
for (i in 1:m) {
x <- sort(rcauchy(n, location = 0, scale = 1))
tmean[i] <- sum(x[(k+1):(n-k)]) / (n-2*k) }
mse.est <- mean(tmean^2)
se.mse <- sqrt(mean((tmean-mean(tmean))^2)) / sqrt(m) 
return(c(mse.est, se.mse))
}

for (k in 1:K) {
mse[k+1, 1:2] <- trimmed.mse(n=n, m=m, k=k, p=1.0) 
mse[k+1, 3:4] <- trimmed.mse(n=n, m=m, k=k, p=.95) 
mse[k+1, 5:6] <- trimmed.mse(n=n, m=m, k=k, p=.9)
}

mse
```
